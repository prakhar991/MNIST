{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b87ca97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7777c64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(flatten=False):\n",
    "    (X_train,Y_train),(X_test, Y_test)=keras.datasets.mnist.load_data()\n",
    "    print(X_train.shape, Y_train.shape, X_test.shape,Y_test.shape)\n",
    "    #normalizations\n",
    "    X_train=X_train.astype(float)/255\n",
    "    X_test=X_test.astype(float)/255\n",
    "    \n",
    "    #data separation\n",
    "    X_train=X_train[:-10000]\n",
    "    X_val=X_train[-10000:]\n",
    "    Y_train=Y_train[:-10000]\n",
    "    Y_val=Y_train[-10000:]\n",
    "    \n",
    "    print(X_val.shape, Y_val.shape)\n",
    "    \n",
    "    if flatten:\n",
    "        X_train=X_train.reshape([X_train.shape[0],-1])\n",
    "        X_val=X_val.reshape([X_val.shape[0], -1])\n",
    "        X_test=X_test.reshape([X_test.shape[0], -1])\n",
    "    return X_train, Y_train, X_val, Y_val, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb97c8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "11501568/11490434 [==============================] - 1s 0us/step\n",
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_val, Y_val, X_test, Y_test=load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eea3463f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x28348a60520>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(Y_train[6])\n",
    "plt.imshow(X_train[6], cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b9e1f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a185bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b2e689",
   "metadata": {},
   "source": [
    "### Changing dimension of input from N * 28 * 28 to N *784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5f0b4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "279dbee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a2e5297",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.reshape((X_train.shape[0],\n",
    "                        X_train.shape[1]* X_train.shape[2]))\n",
    "X_test=X_test.reshape((X_test.shape[0],\n",
    "                      X_test.shape[1]*X_test.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbcfed60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "626055ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=LabelBinarizer().fit_transform(Y_train)\n",
    "Y_test=LabelBinarizer().fit_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b29abd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "567417d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=Y_train.shape[1]\n",
    "num_features=X_train.shape[1]\n",
    "num_output=Y_train.shape[1]\n",
    "num_layers_0=512\n",
    "num_layers_1=256\n",
    "start_learning_rate=0.001\n",
    "regularizer_rate=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67ab26e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f210bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_X=tf.placeholder('float32',\n",
    "                       shape=(None, num_features),\n",
    "                      name=\"input_X\")\n",
    "input_Y=tf.placeholder('float32',\n",
    "                       shape=(None, num_classes),\n",
    "                      name=\"input_Y\")\n",
    "keep_prob=tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4824efc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input layer\n",
    "weight_0=tf.Variable(tf.random_normal([num_features,\n",
    "                num_layers_0],\n",
    "        stddev=1/tf.sqrt(float(num_features))))\n",
    "bias_0=tf.Variable(tf.random_normal([num_layers_0]))\n",
    "\n",
    "weight_1=tf.Variable(tf.random_normal([num_layers_0,\n",
    "                num_layers_1],\n",
    "        stddev=1/tf.sqrt(float(num_layers_0))))\n",
    "bias_1=tf.Variable(tf.random_normal([num_layers_1]))\n",
    "\n",
    "\n",
    "#output layer\n",
    "weight_2=tf.Variable(tf.random_normal([num_layers_1,\n",
    "                num_output],\n",
    "        stddev=1/tf.sqrt(float(num_layers_1))))\n",
    "bias_2=tf.Variable(tf.random_normal([num_output]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8f42b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "hidden_output_0=tf.nn.relu(tf.matmul(input_X,\n",
    "                                     weight_0)+bias_0)\n",
    "\n",
    "hidden_output_0_0=tf.nn.dropout(hidden_output_0,\n",
    "                                keep_prob)\n",
    "\n",
    "hidden_output_1=tf.nn.relu(tf.matmul(hidden_output_0_0,\n",
    "                                     weight_1)+bias_1)\n",
    "hidden_output_1_1=tf.nn.dropout(hidden_output_1,\n",
    "                                keep_prob)\n",
    "\n",
    "predicted_y=tf.sigmoid(tf.matmul(hidden_output_1_1,\n",
    "                                weight_2)+bias_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "274a1950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predicted_y,labels=input_Y))+regularizer_rate*(tf.reduce_mean(tf.square(bias_0)) *tf.reduce_mean(tf.square(bias_1)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed022770",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=tf.train.exponential_decay(start_learning_rate,\n",
    "      0, 5, 0.85, staircase=True)\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate).minimize(loss,\n",
    "            var_list=[weight_0, weight_1, weight_2,\n",
    "                    bias_0, bias_1, bias_2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0b69a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction=tf.equal(tf.argmax(Y_train,1),\n",
    "tf.argmax(predicted_y,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,\n",
    "                                tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7800b938",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "epochs=125\n",
    "dropout_prob=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5893440",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy=[]\n",
    "training_loss=[]\n",
    "testing_accuracy=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b8f0dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af640d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "559d23ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs:0, Train loss:1.57, Train accu: 0.933,Test accu:0.933\n",
      "Epochs:1, Train loss:1.52, Train accu: 0.955,Test accu:0.953\n",
      "Epochs:2, Train loss:1.50, Train accu: 0.966,Test accu:0.961\n",
      "Epochs:3, Train loss:1.49, Train accu: 0.970,Test accu:0.964\n",
      "Epochs:4, Train loss:1.48, Train accu: 0.976,Test accu:0.969\n",
      "Epochs:5, Train loss:1.48, Train accu: 0.980,Test accu:0.972\n",
      "Epochs:6, Train loss:1.48, Train accu: 0.981,Test accu:0.974\n",
      "Epochs:7, Train loss:1.48, Train accu: 0.983,Test accu:0.974\n",
      "Epochs:8, Train loss:1.47, Train accu: 0.986,Test accu:0.975\n",
      "Epochs:9, Train loss:1.47, Train accu: 0.987,Test accu:0.976\n",
      "Epochs:10, Train loss:1.47, Train accu: 0.987,Test accu:0.978\n",
      "Epochs:11, Train loss:1.47, Train accu: 0.988,Test accu:0.979\n",
      "Epochs:12, Train loss:1.47, Train accu: 0.991,Test accu:0.980\n",
      "Epochs:13, Train loss:1.47, Train accu: 0.991,Test accu:0.979\n",
      "Epochs:14, Train loss:1.47, Train accu: 0.992,Test accu:0.981\n",
      "Epochs:15, Train loss:1.47, Train accu: 0.991,Test accu:0.979\n",
      "Epochs:16, Train loss:1.47, Train accu: 0.991,Test accu:0.979\n",
      "Epochs:17, Train loss:1.47, Train accu: 0.992,Test accu:0.980\n",
      "Epochs:18, Train loss:1.47, Train accu: 0.993,Test accu:0.982\n",
      "Epochs:19, Train loss:1.47, Train accu: 0.993,Test accu:0.980\n",
      "Epochs:20, Train loss:1.47, Train accu: 0.993,Test accu:0.981\n",
      "Epochs:21, Train loss:1.47, Train accu: 0.993,Test accu:0.980\n",
      "Epochs:22, Train loss:1.47, Train accu: 0.992,Test accu:0.980\n",
      "Epochs:23, Train loss:1.47, Train accu: 0.993,Test accu:0.979\n",
      "Epochs:24, Train loss:1.47, Train accu: 0.994,Test accu:0.981\n",
      "Epochs:25, Train loss:1.47, Train accu: 0.994,Test accu:0.981\n",
      "Epochs:26, Train loss:1.47, Train accu: 0.995,Test accu:0.982\n",
      "Epochs:27, Train loss:1.47, Train accu: 0.992,Test accu:0.978\n",
      "Epochs:28, Train loss:1.47, Train accu: 0.994,Test accu:0.982\n",
      "Epochs:29, Train loss:1.47, Train accu: 0.995,Test accu:0.983\n",
      "Epochs:30, Train loss:1.47, Train accu: 0.995,Test accu:0.981\n",
      "Epochs:31, Train loss:1.47, Train accu: 0.995,Test accu:0.982\n",
      "Epochs:32, Train loss:1.47, Train accu: 0.995,Test accu:0.982\n",
      "Epochs:33, Train loss:1.47, Train accu: 0.994,Test accu:0.979\n",
      "Epochs:34, Train loss:1.47, Train accu: 0.996,Test accu:0.981\n",
      "Epochs:35, Train loss:1.47, Train accu: 0.996,Test accu:0.983\n",
      "Epochs:36, Train loss:1.47, Train accu: 0.995,Test accu:0.980\n",
      "Epochs:37, Train loss:1.47, Train accu: 0.996,Test accu:0.983\n",
      "Epochs:38, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
      "Epochs:39, Train loss:1.47, Train accu: 0.995,Test accu:0.983\n",
      "Epochs:40, Train loss:1.47, Train accu: 0.996,Test accu:0.983\n",
      "Epochs:41, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
      "Epochs:42, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
      "Epochs:43, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
      "Epochs:44, Train loss:1.47, Train accu: 0.995,Test accu:0.981\n",
      "Epochs:45, Train loss:1.46, Train accu: 0.996,Test accu:0.983\n",
      "Epochs:46, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
      "Epochs:47, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
      "Epochs:48, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
      "Epochs:49, Train loss:1.46, Train accu: 0.996,Test accu:0.980\n",
      "Epochs:50, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
      "Epochs:51, Train loss:1.46, Train accu: 0.997,Test accu:0.982\n",
      "Epochs:52, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
      "Epochs:53, Train loss:1.46, Train accu: 0.996,Test accu:0.983\n",
      "Epochs:54, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
      "Epochs:55, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
      "Epochs:56, Train loss:1.46, Train accu: 0.996,Test accu:0.984\n",
      "Epochs:57, Train loss:1.47, Train accu: 0.994,Test accu:0.979\n",
      "Epochs:58, Train loss:1.46, Train accu: 0.996,Test accu:0.983\n",
      "Epochs:59, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
      "Epochs:60, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
      "Epochs:61, Train loss:1.46, Train accu: 0.995,Test accu:0.981\n",
      "Epochs:62, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
      "Epochs:63, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
      "Epochs:64, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
      "Epochs:65, Train loss:1.46, Train accu: 0.996,Test accu:0.979\n",
      "Epochs:66, Train loss:1.46, Train accu: 0.997,Test accu:0.982\n",
      "Epochs:67, Train loss:1.46, Train accu: 0.997,Test accu:0.983\n",
      "Epochs:68, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
      "Epochs:69, Train loss:1.46, Train accu: 0.997,Test accu:0.983\n",
      "Epochs:70, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
      "Epochs:71, Train loss:1.46, Train accu: 0.995,Test accu:0.981\n",
      "Epochs:72, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
      "Epochs:73, Train loss:1.46, Train accu: 0.997,Test accu:0.982\n",
      "Epochs:74, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
      "Epochs:75, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
      "Epochs:76, Train loss:1.46, Train accu: 0.996,Test accu:0.983\n",
      "Epochs:77, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
      "Epochs:78, Train loss:1.46, Train accu: 0.995,Test accu:0.981\n",
      "Epochs:79, Train loss:1.46, Train accu: 0.997,Test accu:0.982\n",
      "Epochs:80, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
      "Epochs:81, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
      "Epochs:82, Train loss:1.46, Train accu: 0.997,Test accu:0.982\n",
      "Epochs:83, Train loss:1.46, Train accu: 0.996,Test accu:0.980\n",
      "Epochs:84, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
      "Epochs:85, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
      "Epochs:86, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
      "Epochs:87, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
      "Epochs:88, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
      "Epochs:89, Train loss:1.46, Train accu: 0.995,Test accu:0.981\n",
      "Epochs:90, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
      "Epochs:91, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
      "Epochs:92, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
      "Epochs:93, Train loss:1.46, Train accu: 0.997,Test accu:0.983\n",
      "Epochs:94, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
      "Epochs:95, Train loss:1.46, Train accu: 0.995,Test accu:0.980\n",
      "Epochs:96, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
      "Epochs:97, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
      "Epochs:98, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
      "Epochs:99, Train loss:1.46, Train accu: 0.995,Test accu:0.981\n",
      "Epochs:100, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
      "Epochs:101, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
      "Epochs:102, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
      "Epochs:103, Train loss:1.46, Train accu: 0.996,Test accu:0.983\n",
      "Epochs:104, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
      "Epochs:105, Train loss:1.46, Train accu: 0.995,Test accu:0.981\n",
      "Epochs:106, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
      "Epochs:107, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
      "Epochs:108, Train loss:1.46, Train accu: 0.996,Test accu:0.981\n",
      "Epochs:109, Train loss:1.46, Train accu: 0.995,Test accu:0.980\n",
      "Epochs:110, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
      "Epochs:111, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
      "Epochs:112, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
      "Epochs:113, Train loss:1.46, Train accu: 0.996,Test accu:0.983\n",
      "Epochs:114, Train loss:1.46, Train accu: 0.997,Test accu:0.984\n",
      "Epochs:115, Train loss:1.46, Train accu: 0.996,Test accu:0.982\n",
      "Epochs:116, Train loss:1.46, Train accu: 0.997,Test accu:0.982\n",
      "Epochs:117, Train loss:1.46, Train accu: 0.997,Test accu:0.983\n",
      "Epochs:118, Train loss:1.46, Train accu: 0.997,Test accu:0.982\n",
      "Epochs:119, Train loss:1.46, Train accu: 0.995,Test accu:0.981\n",
      "Epochs:120, Train loss:1.46, Train accu: 0.995,Test accu:0.979\n",
      "Epochs:121, Train loss:1.46, Train accu: 0.995,Test accu:0.979\n",
      "Epochs:122, Train loss:1.46, Train accu: 0.995,Test accu:0.981\n",
      "Epochs:123, Train loss:1.46, Train accu: 0.995,Test accu:0.981\n",
      "Epochs:124, Train loss:1.46, Train accu: 0.995,Test accu:0.981\n"
     ]
    }
   ],
   "source": [
    "s.run(tf.global_variables_initializer())\n",
    "for epoch in range(epochs):\n",
    "    arr=np.arange(X_train.shape[0])\n",
    "    np.random.shuffle(arr)\n",
    "    for index in range(0, X_train.shape[0], batch_size):\n",
    "        s.run(optimizer,{input_X:X_train[arr[index:index+batch_size]],\n",
    "                         input_Y:Y_train[arr[index:index+batch_size]],\n",
    "         keep_prob:dropout_prob})\n",
    "        \n",
    "    training_accuracy.append(s.run(accuracy,\n",
    "            feed_dict={input_X:X_train,\n",
    "                      input_Y:Y_train, keep_prob:1}))\n",
    "    testing_accuracy.append(accuracy_score(Y_test.argmax(1),\n",
    "                s.run(predicted_y,{input_X:X_test, keep_prob:1}).argmax(1)))\n",
    "        \n",
    "    training_loss.append(s.run(loss,\n",
    "                        {input_X: X_train,\n",
    "                        input_Y: Y_train, keep_prob:1}))\n",
    "        \n",
    "    print(\"Epochs:{0}, Train loss:{1:.2f}, Train accu: {2:.3f},Test accu:{3:.3f}\".format(epoch,\n",
    "                training_loss[epoch], training_accuracy[epoch],testing_accuracy[epoch]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
